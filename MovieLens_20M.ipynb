{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MovieLens 20M.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN93fR6TOF7mwu2EdGD42ZM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SupratimSircar05/MovieLens-20M/blob/master/MovieLens_20M.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkk2smAThgYW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "5797dc88-867f-4acd-a61e-e62522898c53"
      },
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-20m.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-12 11:57:08--  http://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 198702078 (189M) [application/zip]\n",
            "Saving to: ‘ml-20m.zip’\n",
            "\n",
            "ml-20m.zip          100%[===================>] 189.50M  27.4MB/s    in 7.6s    \n",
            "\n",
            "2020-03-12 11:57:16 (24.9 MB/s) - ‘ml-20m.zip’ saved [198702078/198702078]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2hJdCO1iLAw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "88eea782-3d3a-41ec-ca98-aa0aaf98dfeb"
      },
      "source": [
        "!unzip ml-20m.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ml-20m.zip\n",
            "   creating: ml-20m/\n",
            "  inflating: ml-20m/genome-scores.csv  \n",
            "  inflating: ml-20m/genome-tags.csv  \n",
            "  inflating: ml-20m/links.csv        \n",
            "  inflating: ml-20m/movies.csv       \n",
            "  inflating: ml-20m/ratings.csv      \n",
            "  inflating: ml-20m/README.txt       \n",
            "  inflating: ml-20m/tags.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97M4QAgKiigq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8ed876b1-d05b-45ca-a6eb-4ac72ee8885f"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtxI6U_Siqb4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aca23337-308d-41bf-fa1d-8a9c03490ac4"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ml-20m\tml-20m.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fymL1LNciq8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "deb60f00-a1ef-45bf-8280-3ce5f0f952d3"
      },
      "source": [
        "!ls ml-20m"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "genome-scores.csv  links.csv   ratings.csv  tags.csv\n",
            "genome-tags.csv    movies.csv  README.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3-Cjr1kiwVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0z7EL9Ki92t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "54dacde6-80a6-455d-86e9-47ecd7134fb4"
      },
      "source": [
        "print('movies.csv: ')\n",
        "movies = pd.read_csv('/content/ml-20m/movies.csv',index_col=None)\n",
        "movies.describe()\n",
        "movies.head(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "movies.csv: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movieId  ...                                       genres\n",
              "0        1  ...  Adventure|Animation|Children|Comedy|Fantasy\n",
              "1        2  ...                   Adventure|Children|Fantasy\n",
              "2        3  ...                               Comedy|Romance\n",
              "3        4  ...                         Comedy|Drama|Romance\n",
              "4        5  ...                                       Comedy\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YLaftc5jqTk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "993d5a26-65e4-4af0-fc27-734f447fee43"
      },
      "source": [
        "print('ratings.csv: ')\n",
        "ratings = pd.read_csv('/content/ml-20m/ratings.csv',index_col=None)\n",
        "ratings.describe()\n",
        "ratings.head(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ratings.csv: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112486027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484580</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating   timestamp\n",
              "0       1        2     3.5  1112486027\n",
              "1       1       29     3.5  1112484676\n",
              "2       1       32     3.5  1112484819\n",
              "3       1       47     3.5  1112484727\n",
              "4       1       50     3.5  1112484580"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsvlNN-CkPl6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "373c0b3d-2579-4e90-f015-7f6e2ab28fff"
      },
      "source": [
        "print('tags.csv: ')\n",
        "tags = pd.read_csv('/content/ml-20m/tags.csv',index_col=None)\n",
        "tags.describe()\n",
        "tags.head(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tags.csv: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>tag</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18</td>\n",
              "      <td>4141</td>\n",
              "      <td>Mark Waters</td>\n",
              "      <td>1240597180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>65</td>\n",
              "      <td>208</td>\n",
              "      <td>dark hero</td>\n",
              "      <td>1368150078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65</td>\n",
              "      <td>353</td>\n",
              "      <td>dark hero</td>\n",
              "      <td>1368150079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>65</td>\n",
              "      <td>521</td>\n",
              "      <td>noir thriller</td>\n",
              "      <td>1368149983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65</td>\n",
              "      <td>592</td>\n",
              "      <td>dark hero</td>\n",
              "      <td>1368150078</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId            tag   timestamp\n",
              "0      18     4141    Mark Waters  1240597180\n",
              "1      65      208      dark hero  1368150078\n",
              "2      65      353      dark hero  1368150079\n",
              "3      65      521  noir thriller  1368149983\n",
              "4      65      592      dark hero  1368150078"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE7mwIwTkatF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "c559a796-bc79-449c-feb1-6a8f3d036914"
      },
      "source": [
        "print('genome-tags.csv: ')\n",
        "genome_tags = pd.read_csv('/content/ml-20m/genome-tags.csv',index_col=None)\n",
        "genome_tags.describe()\n",
        "genome_tags.head(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "genome-tags.csv: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tagId</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>007 (series)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>18th century</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1920s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1930s</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tagId           tag\n",
              "0      1           007\n",
              "1      2  007 (series)\n",
              "2      3  18th century\n",
              "3      4         1920s\n",
              "4      5         1930s"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QmkqwftkiD6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "3d374b5f-b4ef-4c9d-e40f-c74069a6d507"
      },
      "source": [
        "print('genome-scores.csv: ')\n",
        "genome_scores = pd.read_csv('/content/ml-20m/genome-scores.csv',index_col=None)\n",
        "genome_scores.describe()\n",
        "genome_scores.head(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "genome-scores.csv: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>tagId</th>\n",
              "      <th>relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.02500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.02500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.05775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.09675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.14675</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movieId  tagId  relevance\n",
              "0        1      1    0.02500\n",
              "1        1      2    0.02500\n",
              "2        1      3    0.05775\n",
              "3        1      4    0.09675\n",
              "4        1      5    0.14675"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V08gq0-Ekoob",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "fced5a2f-c50b-45a2-e2b5-580cb0985a97"
      },
      "source": [
        "print('The number of movies: {}'.format(movies.count()['movieId']))\n",
        "print('The number of ratings: {}'.format(ratings.count()['movieId']))\n",
        "\n",
        "print('')\n",
        "print('min value of rating: {}'.format(ratings['rating'].min()))\n",
        "print('max value of rating: {}'.format(ratings['rating'].max()))\n",
        "\n",
        "print('')\n",
        "ra = ratings.groupby(ratings['userId']).count()\n",
        "print('The number of user in ratings.csv: {}'.format(ra.count()[0]))\n",
        "print('The minimum number of ratings per user in ratings.csv: {}'.format(ra['movieId'].min()))\n",
        "print('The maximun number of ratings per user in ratings.csv: {}'.format(ra['movieId'].max()))\n",
        "\n",
        "print('')\n",
        "ra = ratings.groupby(ratings['movieId']).count()\n",
        "print('The number of movies in ratings.csv: {}'.format(ra.count()[0]))\n",
        "print('The minimum number of ratings per movie in ratings.csv: {}'.format(ra['userId'].min()))\n",
        "print('The maximun number of ratings per movie in ratings.csv: {}'.format(ra['userId'].max()))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of movies: 27278\n",
            "The number of ratings: 20000263\n",
            "\n",
            "min value of rating: 0.5\n",
            "max value of rating: 5.0\n",
            "\n",
            "The number of user in ratings.csv: 138493\n",
            "The minimum number of ratings per user in ratings.csv: 20\n",
            "The maximun number of ratings per user in ratings.csv: 9254\n",
            "\n",
            "The number of movies in ratings.csv: 26744\n",
            "The minimum number of ratings per movie in ratings.csv: 1\n",
            "The maximun number of ratings per movie in ratings.csv: 67310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_RsJWnfkwvl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "eef74c7a-e56b-461a-be0d-3c0cc5519361"
      },
      "source": [
        "print('The number of tags in tags.csv: {}'.format(tags.count()['userId']))\n",
        "print('The number of tags in genome-tags.csv: {}'.format(genome_tags.count()['tagId']))\n",
        "\n",
        "print('')\n",
        "ra = tags.groupby(tags['userId']).count()\n",
        "print('The number of user in tags.csv: {}'.format(ra.count()[0]))\n",
        "print('The minimum number of tags per user in tags.csv: {}'.format(ra['movieId'].min()))\n",
        "print('The maximun number of tags per user in tags.csv: {}'.format(ra['movieId'].max()))\n",
        "\n",
        "print('')\n",
        "ra = tags.groupby(tags['movieId']).count()\n",
        "print('The number of movies in tags.csv: {}'.format(ra.count()[0]))\n",
        "print('The minimum number of tags per movie in tags.csv: {}'.format(ra['userId'].min()))\n",
        "print('The maximun number of tags per movie in tags.csv: {}'.format(ra['userId'].max()))\n",
        "\n",
        "print('')\n",
        "tags_mer = pd.merge(tags, genome_tags, how='left', left_on='tag', right_on='tag')\n",
        "print('The number of tags in tags.csv but not in genome-tags.csv: {}'.format(tags_mer[(tags_mer['tagId'].isnull())].count()[0]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of tags in tags.csv: 465564\n",
            "The number of tags in genome-tags.csv: 1128\n",
            "\n",
            "The number of user in tags.csv: 7801\n",
            "The minimum number of tags per user in tags.csv: 1\n",
            "The maximun number of tags per user in tags.csv: 20356\n",
            "\n",
            "The number of movies in tags.csv: 19545\n",
            "The minimum number of tags per movie in tags.csv: 1\n",
            "The maximun number of tags per movie in tags.csv: 1994\n",
            "\n",
            "The number of tags in tags.csv but not in genome-tags.csv: 247993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgYUegjyk1eL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "7e3e2f34-e57a-4ed0-bc1c-7743abb1abdb"
      },
      "source": [
        "print('The length of genome_scores.csv: {}'.format(genome_scores.count()['movieId']))\n",
        "print('max value of relevance from genome_scores.csv: {}'.format(genome_scores['relevance'].max()))\n",
        "print('min value of relevance from genome_scores.csv: {}'.format(genome_scores['relevance'].min()))\n",
        "\n",
        "print('')\n",
        "ra = genome_scores.groupby(genome_scores['movieId']).count()\n",
        "print('The number of movies in genome_scores.csv: {}'.format(ra.count()[0]))\n",
        "print('The minimum number of tags per movie in genome_scores.csv: {}'.format(ra['tagId'].min()))\n",
        "print('The maximun number of tags per movie in genome_scores.csv: {}'.format(ra['tagId'].max()))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of genome_scores.csv: 11709768\n",
            "max value of relevance from genome_scores.csv: 1.0\n",
            "min value of relevance from genome_scores.csv: 0.00024999999999997247\n",
            "\n",
            "The number of movies in genome_scores.csv: 10381\n",
            "The minimum number of tags per movie in genome_scores.csv: 1128\n",
            "The maximun number of tags per movie in genome_scores.csv: 1128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI1pVRxmk7RQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "a4fbe3a5-5423-4ac3-9575-9d04251efa67"
      },
      "source": [
        "# Analysis of the relevant data of movies in both genome_scores.csv and ratings.csv:\n",
        "\n",
        "genome_scores_group = genome_scores.groupby(genome_scores['movieId']).mean()\n",
        "ratings_group = ratings.groupby(ratings['movieId']).mean()\n",
        "rat_ge_merge = pd.merge(ratings_group, genome_scores_group, how='inner', left_on='movieId', right_on='movieId')\n",
        "number = rat_ge_merge.count()[0]\n",
        "print('Number of movies in both genome_scores.csv and ratings.csv: {}. Take up {}% of ratings.csv'\\\n",
        "      .format(number, round(number/19545*100)))\n",
        "\n",
        "ratings_genome_merge = pd.merge(ratings, genome_scores_group, how='inner', left_on='movieId', right_on='movieId')\n",
        "number = ratings_genome_merge.count()[0]\n",
        "print('Number of ratings where its movieId in genome_scores.csv: {}. Take up {}% of ratings.csv'\\\n",
        "      .format(number, round(number/20000263*100)))\n",
        "\n",
        "print('')\n",
        "ra = ratings_genome_merge.groupby(ratings_genome_merge['userId']).count()\n",
        "number = ra.count()[0]\n",
        "print('{} users rate the movies appearing in both genome_scores.csv and ratings.csv. Take up {}% of ratings.csv'\\\n",
        "      .format(number, round(number/138493*100)))\n",
        "print('Minimum number of ratings per user for the movies appearing in both genome_scores.csv and ratings.csv: {}'.format(ra['movieId'].min()))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of movies in both genome_scores.csv and ratings.csv: 10370. Take up 53.0% of ratings.csv\n",
            "Number of ratings where its movieId in genome_scores.csv: 19800443. Take up 99.0% of ratings.csv\n",
            "\n",
            "138493 users rate the movies appearing in both genome_scores.csv and ratings.csv. Take up 100.0% of ratings.csv\n",
            "Minimum number of ratings per user for the movies appearing in both genome_scores.csv and ratings.csv: 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1m-urwklC8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocess data\n",
        "# The first column of features is userId, the next is movieId.\n",
        "# The only one column of target is rating.\n",
        "\n",
        "remove_fields = ['timestamp','tagId','relevance','rating']\n",
        "target = ratings_genome_merge['rating']\n",
        "feature = ratings_genome_merge.drop(remove_fields, axis=1)\n",
        "features = feature.values\n",
        "target = target.values\n",
        "\n",
        "genome_scores_dict = {}\n",
        "for i in range(10381):\n",
        "    m_id = -1\n",
        "    vec = []\n",
        "    for j in range(1128):\n",
        "        index = j + i * 1128\n",
        "        if m_id < 0:\n",
        "            m_id = genome_scores['movieId'][index]\n",
        "        assert genome_scores['movieId'][index] == m_id\n",
        "        assert genome_scores['tagId'][index] == j + 1\n",
        "        vec.append(genome_scores['relevance'][index])\n",
        "    genome_scores_dict[str(m_id)] = vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lpRcfrOlcLw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c67d0f61-fd08-4086-a7cf-d5f37eb67ba0"
      },
      "source": [
        "# Using train_test_split here is not the best. \n",
        "# The better method is to split the data according the userId, which makes sure every user is in the test set.\n",
        "# We can make it easily and quickly ( We have already included 99.86% users).\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_features,test_features, train_target, test_target = train_test_split(features,  \n",
        "                                                           target,  \n",
        "                                                           test_size = 0.2,  \n",
        "                                                           random_state = 0)\n",
        "\n",
        "dict_t = {}\n",
        "dict_t['userId'] = test_features[:,0]\n",
        "dict_t['movieId'] = test_features[:,1]\n",
        "pd_data = pd.DataFrame.from_dict(dict_t)\n",
        "user_test = pd_data.groupby(pd_data['userId']).count().count()[0]\n",
        "\n",
        "print('{}% users in test set ({} users)'.format(round(user_test/138493*100, 2), user_test ))\n",
        "\n",
        "dict_t = {}\n",
        "dict_t['userId'] = train_features[:,0]\n",
        "dict_t['movieId'] = train_features[:,1]\n",
        "pd_data = pd.DataFrame.from_dict(dict_t)\n",
        "user_train = pd_data.groupby(pd_data['userId']).count().count()[0]\n",
        "\n",
        "print('{}% users in training set ({} users)'.format(round(user_train/138493*100, 2), user_train ))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.86% users in test set (138294 users)\n",
            "100.0% users in training set (138493 users)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBfc4FwHl2rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save preprocess data to '/content/verify_assumption.data'\n",
        "pickle.dump((train_features, test_features, train_target, test_target, genome_scores_dict), open('/content/verify_assumption.data', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ofd3UlzmOFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load preprocess data from '/content/verify_assumption.data'\n",
        "train_features, test_features, train_target, test_target, genome_scores_dict = pickle.load(open('/content/verify_assumption.data', mode='rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVy75fPOmYhy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 768  # batch size \n",
        "lr = 1e-3         # learning rate\n",
        "feature_dim = 512 # Dimension of movie or user feature vector\n",
        "Epoch = 6         # train epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6OYmSoNqkdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Verify_Assumption_Model(nn.Module):\n",
        "    \"\"\"The whole model\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Verify_Assumption_Model, self).__init__()\n",
        "        # self.emb_user = nn.Embedding(138493 + 1, 512, # use ratings['userId'].max()+1 instead of 138493+1 is better\n",
        "        #                     padding_idx=0)\n",
        "        self.emb_user = nn.Embedding(ratings['userId'].max()+1, 512,\n",
        "                            padding_idx=0)\n",
        "        \n",
        "        self.movie_transfrom = nn.Sequential(\n",
        "            nn.Linear(1128, 512),\n",
        "            nn.Tanh(), # activation function can not be the final layer of Sequential. But it can be the first one.\n",
        "            nn.Linear(512, 512)\n",
        "        )\n",
        "    \n",
        "    def forward(self, userId, movieVector):\n",
        "        v_user  = self.emb_user(userId)\n",
        "        v_movie = self.movie_transfrom(movieVector)\n",
        "        v_user.unsqueeze_(1)\n",
        "        v_movie.unsqueeze_(2)\n",
        "        return torch.bmm(v_user,v_movie)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYzhni0ArKfR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5119cdc5-3937-4dfb-c8dc-890dfb93ef7d"
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "len_train_features = len(train_features)\n",
        "index = 0\n",
        "model = Verify_Assumption_Model()\n",
        "model.cuda()\n",
        "\n",
        "loss_fn = torch.nn.MSELoss(reduce=False, size_average=False)\n",
        "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
        "                               lr=lr, weight_decay=0)\n",
        "losses = {'train':[], 'test':[]}\n",
        "\n",
        "for epoch_i in range(Epoch):\n",
        "    index = 0\n",
        "    while index <= len_train_features:\n",
        "        index_end = index + batch_size\n",
        "        if index_end >= len_train_features:\n",
        "            batch_train = train_features[index:len_train_features]\n",
        "            batch_train_target = train_target[index:len_train_features]\n",
        "        else:\n",
        "            batch_train = train_features[index:index_end]\n",
        "            batch_train_target = train_target[index:index_end]\n",
        "\n",
        "        #assert len(batch_train) == len(batch_train_target)\n",
        "\n",
        "        userId = batch_train[:,0]\n",
        "        movieId = batch_train[:,1]\n",
        "        movie_vec = []\n",
        "        for i in range(len(movieId)):\n",
        "            movie_vec.append(genome_scores_dict[str(movieId[i])])\n",
        "\n",
        "\n",
        "        rating = model(torch.tensor(userId, requires_grad = False).cuda(),torch.tensor(movie_vec, requires_grad = False).cuda())\n",
        "        rating = rating.squeeze_(1).squeeze_(1)\n",
        "        loss = sum(loss_fn(rating,torch.tensor(batch_train_target,dtype=torch.float32,requires_grad = False).cuda()))\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        losses['train'].append(loss.detach().cpu().numpy())\n",
        "        opt.step()\n",
        "        if len(losses['train']) % 500 == 0:\n",
        "            print('Epoch {:>3} Batch {:>4}/15840354   train_loss = {:.3f}'.format(\n",
        "                        epoch_i,\n",
        "                        index,\n",
        "                        losses['train'][len(losses['train'])-1]))\n",
        "        index += batch_size\n",
        "        \n",
        "    # test\n",
        "    \n",
        "    len_test_features = len(test_features)\n",
        "    index = 0\n",
        "\n",
        "    while index <= len_test_features:\n",
        "        index_end = index + batch_size\n",
        "        if index_end >= len_train_features:\n",
        "            batch_train = test_features[index:len_train_features]\n",
        "            batch_train_target = test_target[index:len_train_features]\n",
        "        else:\n",
        "            batch_train = test_features[index:index_end]\n",
        "            batch_train_target = test_target[index:index_end]\n",
        "\n",
        "        #assert len(batch_train) == len(batch_train_target)\n",
        "\n",
        "        userId = batch_train[:,0]\n",
        "        movieId = batch_train[:,1]\n",
        "        movie_vec = []\n",
        "        for i in range(len(movieId)):\n",
        "            movie_vec.append(genome_scores_dict[str(movieId[i])])\n",
        "\n",
        "\n",
        "        rating = model(torch.tensor(userId, requires_grad = False).cuda(),torch.tensor(movie_vec, requires_grad = False).cuda())\n",
        "        rating = rating.squeeze_(1).squeeze_(1)\n",
        "        loss = sum(loss_fn(rating,torch.tensor(batch_train_target,dtype=torch.float32,requires_grad = False).cuda()))\n",
        "\n",
        "        losses['test'].append(loss.detach().cpu().numpy())\n",
        "        if len(losses['test']) % 500 == 0:\n",
        "            print('Epoch {:>3} Batch {:>4}/3960089   test_loss = {:.3f}'.format(\n",
        "                        epoch_i,\n",
        "                        index,\n",
        "                        losses['test'][len(losses['test'])-1]))\n",
        "        index += batch_size"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch   0 Batch 383232/15840354   train_loss = 11731.252\n",
            "Epoch   0 Batch 767232/15840354   train_loss = 7939.066\n",
            "Epoch   0 Batch 1151232/15840354   train_loss = 5150.809\n",
            "Epoch   0 Batch 1535232/15840354   train_loss = 2980.807\n",
            "Epoch   0 Batch 1919232/15840354   train_loss = 2632.171\n",
            "Epoch   0 Batch 2303232/15840354   train_loss = 1874.893\n",
            "Epoch   0 Batch 2687232/15840354   train_loss = 1289.654\n",
            "Epoch   0 Batch 3071232/15840354   train_loss = 1311.792\n",
            "Epoch   0 Batch 3455232/15840354   train_loss = 1220.564\n",
            "Epoch   0 Batch 3839232/15840354   train_loss = 1209.877\n",
            "Epoch   0 Batch 4223232/15840354   train_loss = 1461.529\n",
            "Epoch   0 Batch 4607232/15840354   train_loss = 1435.075\n",
            "Epoch   0 Batch 4991232/15840354   train_loss = 1197.248\n",
            "Epoch   0 Batch 5375232/15840354   train_loss = 1375.660\n",
            "Epoch   0 Batch 5759232/15840354   train_loss = 1166.945\n",
            "Epoch   0 Batch 6143232/15840354   train_loss = 1189.283\n",
            "Epoch   0 Batch 6527232/15840354   train_loss = 1220.326\n",
            "Epoch   0 Batch 6911232/15840354   train_loss = 1128.382\n",
            "Epoch   0 Batch 7295232/15840354   train_loss = 1280.552\n",
            "Epoch   0 Batch 7679232/15840354   train_loss = 1152.450\n",
            "Epoch   0 Batch 8063232/15840354   train_loss = 1219.724\n",
            "Epoch   0 Batch 8447232/15840354   train_loss = 1144.662\n",
            "Epoch   0 Batch 8831232/15840354   train_loss = 1246.019\n",
            "Epoch   0 Batch 9215232/15840354   train_loss = 1142.895\n",
            "Epoch   0 Batch 9599232/15840354   train_loss = 1037.818\n",
            "Epoch   0 Batch 9983232/15840354   train_loss = 1095.543\n",
            "Epoch   0 Batch 10367232/15840354   train_loss = 1045.306\n",
            "Epoch   0 Batch 10751232/15840354   train_loss = 1084.005\n",
            "Epoch   0 Batch 11135232/15840354   train_loss = 1047.134\n",
            "Epoch   0 Batch 11519232/15840354   train_loss = 1050.217\n",
            "Epoch   0 Batch 11903232/15840354   train_loss = 1138.543\n",
            "Epoch   0 Batch 12287232/15840354   train_loss = 1155.948\n",
            "Epoch   0 Batch 12671232/15840354   train_loss = 1096.423\n",
            "Epoch   0 Batch 13055232/15840354   train_loss = 1079.105\n",
            "Epoch   0 Batch 13439232/15840354   train_loss = 1070.905\n",
            "Epoch   0 Batch 13823232/15840354   train_loss = 1140.122\n",
            "Epoch   0 Batch 14207232/15840354   train_loss = 1036.687\n",
            "Epoch   0 Batch 14591232/15840354   train_loss = 1117.729\n",
            "Epoch   0 Batch 14975232/15840354   train_loss = 1148.954\n",
            "Epoch   0 Batch 15359232/15840354   train_loss = 1116.172\n",
            "Epoch   0 Batch 15743232/15840354   train_loss = 1103.706\n",
            "Epoch   0 Batch 383232/3960089   test_loss = 1099.392\n",
            "Epoch   0 Batch 767232/3960089   test_loss = 1023.552\n",
            "Epoch   0 Batch 1151232/3960089   test_loss = 1095.126\n",
            "Epoch   0 Batch 1535232/3960089   test_loss = 1211.639\n",
            "Epoch   0 Batch 1919232/3960089   test_loss = 1219.562\n",
            "Epoch   0 Batch 2303232/3960089   test_loss = 1249.867\n",
            "Epoch   0 Batch 2687232/3960089   test_loss = 1100.371\n",
            "Epoch   0 Batch 3071232/3960089   test_loss = 1258.774\n",
            "Epoch   0 Batch 3455232/3960089   test_loss = 1132.322\n",
            "Epoch   0 Batch 3839232/3960089   test_loss = 1279.525\n",
            "Epoch   1 Batch 286464/15840354   train_loss = 989.349\n",
            "Epoch   1 Batch 670464/15840354   train_loss = 948.109\n",
            "Epoch   1 Batch 1054464/15840354   train_loss = 1030.852\n",
            "Epoch   1 Batch 1438464/15840354   train_loss = 926.798\n",
            "Epoch   1 Batch 1822464/15840354   train_loss = 1105.030\n",
            "Epoch   1 Batch 2206464/15840354   train_loss = 1073.056\n",
            "Epoch   1 Batch 2590464/15840354   train_loss = 1049.631\n",
            "Epoch   1 Batch 2974464/15840354   train_loss = 1103.010\n",
            "Epoch   1 Batch 3358464/15840354   train_loss = 1012.405\n",
            "Epoch   1 Batch 3742464/15840354   train_loss = 1224.266\n",
            "Epoch   1 Batch 4126464/15840354   train_loss = 1105.155\n",
            "Epoch   1 Batch 4510464/15840354   train_loss = 982.726\n",
            "Epoch   1 Batch 4894464/15840354   train_loss = 1041.374\n",
            "Epoch   1 Batch 5278464/15840354   train_loss = 945.651\n",
            "Epoch   1 Batch 5662464/15840354   train_loss = 952.491\n",
            "Epoch   1 Batch 6046464/15840354   train_loss = 1102.966\n",
            "Epoch   1 Batch 6430464/15840354   train_loss = 1186.519\n",
            "Epoch   1 Batch 6814464/15840354   train_loss = 1026.207\n",
            "Epoch   1 Batch 7198464/15840354   train_loss = 1009.807\n",
            "Epoch   1 Batch 7582464/15840354   train_loss = 1073.814\n",
            "Epoch   1 Batch 7966464/15840354   train_loss = 1050.273\n",
            "Epoch   1 Batch 8350464/15840354   train_loss = 1011.345\n",
            "Epoch   1 Batch 8734464/15840354   train_loss = 1058.347\n",
            "Epoch   1 Batch 9118464/15840354   train_loss = 962.565\n",
            "Epoch   1 Batch 9502464/15840354   train_loss = 1066.234\n",
            "Epoch   1 Batch 9886464/15840354   train_loss = 1025.239\n",
            "Epoch   1 Batch 10270464/15840354   train_loss = 920.347\n",
            "Epoch   1 Batch 10654464/15840354   train_loss = 971.343\n",
            "Epoch   1 Batch 11038464/15840354   train_loss = 1119.268\n",
            "Epoch   1 Batch 11422464/15840354   train_loss = 1020.758\n",
            "Epoch   1 Batch 11806464/15840354   train_loss = 901.438\n",
            "Epoch   1 Batch 12190464/15840354   train_loss = 1094.391\n",
            "Epoch   1 Batch 12574464/15840354   train_loss = 995.050\n",
            "Epoch   1 Batch 12958464/15840354   train_loss = 852.319\n",
            "Epoch   1 Batch 13342464/15840354   train_loss = 945.563\n",
            "Epoch   1 Batch 13726464/15840354   train_loss = 1045.936\n",
            "Epoch   1 Batch 14110464/15840354   train_loss = 1132.805\n",
            "Epoch   1 Batch 14494464/15840354   train_loss = 1035.802\n",
            "Epoch   1 Batch 14878464/15840354   train_loss = 1045.526\n",
            "Epoch   1 Batch 15262464/15840354   train_loss = 882.765\n",
            "Epoch   1 Batch 15646464/15840354   train_loss = 966.013\n",
            "Epoch   1 Batch 262656/3960089   test_loss = 1080.401\n",
            "Epoch   1 Batch 646656/3960089   test_loss = 1089.780\n",
            "Epoch   1 Batch 1030656/3960089   test_loss = 1053.173\n",
            "Epoch   1 Batch 1414656/3960089   test_loss = 1039.188\n",
            "Epoch   1 Batch 1798656/3960089   test_loss = 1063.126\n",
            "Epoch   1 Batch 2182656/3960089   test_loss = 1063.812\n",
            "Epoch   1 Batch 2566656/3960089   test_loss = 978.940\n",
            "Epoch   1 Batch 2950656/3960089   test_loss = 1039.531\n",
            "Epoch   1 Batch 3334656/3960089   test_loss = 997.748\n",
            "Epoch   1 Batch 3718656/3960089   test_loss = 944.671\n",
            "Epoch   2 Batch 189696/15840354   train_loss = 1022.788\n",
            "Epoch   2 Batch 573696/15840354   train_loss = 987.362\n",
            "Epoch   2 Batch 957696/15840354   train_loss = 872.322\n",
            "Epoch   2 Batch 1341696/15840354   train_loss = 966.578\n",
            "Epoch   2 Batch 1725696/15840354   train_loss = 915.367\n",
            "Epoch   2 Batch 2109696/15840354   train_loss = 881.381\n",
            "Epoch   2 Batch 2493696/15840354   train_loss = 878.725\n",
            "Epoch   2 Batch 2877696/15840354   train_loss = 941.500\n",
            "Epoch   2 Batch 3261696/15840354   train_loss = 1011.990\n",
            "Epoch   2 Batch 3645696/15840354   train_loss = 976.398\n",
            "Epoch   2 Batch 4029696/15840354   train_loss = 1029.353\n",
            "Epoch   2 Batch 4413696/15840354   train_loss = 894.490\n",
            "Epoch   2 Batch 4797696/15840354   train_loss = 872.061\n",
            "Epoch   2 Batch 5181696/15840354   train_loss = 904.161\n",
            "Epoch   2 Batch 5565696/15840354   train_loss = 1022.727\n",
            "Epoch   2 Batch 5949696/15840354   train_loss = 918.425\n",
            "Epoch   2 Batch 6333696/15840354   train_loss = 904.036\n",
            "Epoch   2 Batch 6717696/15840354   train_loss = 912.200\n",
            "Epoch   2 Batch 7101696/15840354   train_loss = 895.248\n",
            "Epoch   2 Batch 7485696/15840354   train_loss = 998.944\n",
            "Epoch   2 Batch 7869696/15840354   train_loss = 897.232\n",
            "Epoch   2 Batch 8253696/15840354   train_loss = 1028.228\n",
            "Epoch   2 Batch 8637696/15840354   train_loss = 1032.871\n",
            "Epoch   2 Batch 9021696/15840354   train_loss = 935.334\n",
            "Epoch   2 Batch 9405696/15840354   train_loss = 961.757\n",
            "Epoch   2 Batch 9789696/15840354   train_loss = 935.651\n",
            "Epoch   2 Batch 10173696/15840354   train_loss = 950.931\n",
            "Epoch   2 Batch 10557696/15840354   train_loss = 891.743\n",
            "Epoch   2 Batch 10941696/15840354   train_loss = 964.495\n",
            "Epoch   2 Batch 11325696/15840354   train_loss = 973.946\n",
            "Epoch   2 Batch 11709696/15840354   train_loss = 1006.599\n",
            "Epoch   2 Batch 12093696/15840354   train_loss = 979.611\n",
            "Epoch   2 Batch 12477696/15840354   train_loss = 903.998\n",
            "Epoch   2 Batch 12861696/15840354   train_loss = 921.611\n",
            "Epoch   2 Batch 13245696/15840354   train_loss = 1009.032\n",
            "Epoch   2 Batch 13629696/15840354   train_loss = 807.101\n",
            "Epoch   2 Batch 14013696/15840354   train_loss = 920.174\n",
            "Epoch   2 Batch 14397696/15840354   train_loss = 949.783\n",
            "Epoch   2 Batch 14781696/15840354   train_loss = 973.281\n",
            "Epoch   2 Batch 15165696/15840354   train_loss = 939.539\n",
            "Epoch   2 Batch 15549696/15840354   train_loss = 900.986\n",
            "Epoch   2 Batch 142080/3960089   test_loss = 1244.614\n",
            "Epoch   2 Batch 526080/3960089   test_loss = 1183.772\n",
            "Epoch   2 Batch 910080/3960089   test_loss = 1115.595\n",
            "Epoch   2 Batch 1294080/3960089   test_loss = 1118.022\n",
            "Epoch   2 Batch 1678080/3960089   test_loss = 1263.695\n",
            "Epoch   2 Batch 2062080/3960089   test_loss = 1162.210\n",
            "Epoch   2 Batch 2446080/3960089   test_loss = 1101.119\n",
            "Epoch   2 Batch 2830080/3960089   test_loss = 1143.224\n",
            "Epoch   2 Batch 3214080/3960089   test_loss = 1243.629\n",
            "Epoch   2 Batch 3598080/3960089   test_loss = 1181.602\n",
            "Epoch   3 Batch 92928/15840354   train_loss = 978.355\n",
            "Epoch   3 Batch 476928/15840354   train_loss = 983.273\n",
            "Epoch   3 Batch 860928/15840354   train_loss = 898.408\n",
            "Epoch   3 Batch 1244928/15840354   train_loss = 973.616\n",
            "Epoch   3 Batch 1628928/15840354   train_loss = 898.356\n",
            "Epoch   3 Batch 2012928/15840354   train_loss = 1077.894\n",
            "Epoch   3 Batch 2396928/15840354   train_loss = 1062.092\n",
            "Epoch   3 Batch 2780928/15840354   train_loss = 877.168\n",
            "Epoch   3 Batch 3164928/15840354   train_loss = 891.279\n",
            "Epoch   3 Batch 3548928/15840354   train_loss = 867.742\n",
            "Epoch   3 Batch 3932928/15840354   train_loss = 949.476\n",
            "Epoch   3 Batch 4316928/15840354   train_loss = 955.581\n",
            "Epoch   3 Batch 4700928/15840354   train_loss = 907.286\n",
            "Epoch   3 Batch 5084928/15840354   train_loss = 1053.503\n",
            "Epoch   3 Batch 5468928/15840354   train_loss = 963.925\n",
            "Epoch   3 Batch 5852928/15840354   train_loss = 926.895\n",
            "Epoch   3 Batch 6236928/15840354   train_loss = 875.597\n",
            "Epoch   3 Batch 6620928/15840354   train_loss = 926.096\n",
            "Epoch   3 Batch 7004928/15840354   train_loss = 1021.459\n",
            "Epoch   3 Batch 7388928/15840354   train_loss = 896.748\n",
            "Epoch   3 Batch 7772928/15840354   train_loss = 969.528\n",
            "Epoch   3 Batch 8156928/15840354   train_loss = 847.835\n",
            "Epoch   3 Batch 8540928/15840354   train_loss = 804.294\n",
            "Epoch   3 Batch 8924928/15840354   train_loss = 981.272\n",
            "Epoch   3 Batch 9308928/15840354   train_loss = 1054.466\n",
            "Epoch   3 Batch 9692928/15840354   train_loss = 954.212\n",
            "Epoch   3 Batch 10076928/15840354   train_loss = 939.053\n",
            "Epoch   3 Batch 10460928/15840354   train_loss = 853.165\n",
            "Epoch   3 Batch 10844928/15840354   train_loss = 789.281\n",
            "Epoch   3 Batch 11228928/15840354   train_loss = 980.224\n",
            "Epoch   3 Batch 11612928/15840354   train_loss = 937.581\n",
            "Epoch   3 Batch 11996928/15840354   train_loss = 949.830\n",
            "Epoch   3 Batch 12380928/15840354   train_loss = 883.849\n",
            "Epoch   3 Batch 12764928/15840354   train_loss = 856.906\n",
            "Epoch   3 Batch 13148928/15840354   train_loss = 872.513\n",
            "Epoch   3 Batch 13532928/15840354   train_loss = 891.784\n",
            "Epoch   3 Batch 13916928/15840354   train_loss = 938.838\n",
            "Epoch   3 Batch 14300928/15840354   train_loss = 778.810\n",
            "Epoch   3 Batch 14684928/15840354   train_loss = 897.556\n",
            "Epoch   3 Batch 15068928/15840354   train_loss = 911.597\n",
            "Epoch   3 Batch 15452928/15840354   train_loss = 997.419\n",
            "Epoch   3 Batch 15836928/15840354   train_loss = 848.827\n",
            "Epoch   3 Batch 21504/3960089   test_loss = 1235.925\n",
            "Epoch   3 Batch 405504/3960089   test_loss = 1137.176\n",
            "Epoch   3 Batch 789504/3960089   test_loss = 1230.731\n",
            "Epoch   3 Batch 1173504/3960089   test_loss = 1141.910\n",
            "Epoch   3 Batch 1557504/3960089   test_loss = 1274.920\n",
            "Epoch   3 Batch 1941504/3960089   test_loss = 1220.107\n",
            "Epoch   3 Batch 2325504/3960089   test_loss = 1244.830\n",
            "Epoch   3 Batch 2709504/3960089   test_loss = 1266.911\n",
            "Epoch   3 Batch 3093504/3960089   test_loss = 1199.740\n",
            "Epoch   3 Batch 3477504/3960089   test_loss = 1077.753\n",
            "Epoch   3 Batch 3861504/3960089   test_loss = 1138.800\n",
            "Epoch   4 Batch 380160/15840354   train_loss = 913.162\n",
            "Epoch   4 Batch 764160/15840354   train_loss = 862.268\n",
            "Epoch   4 Batch 1148160/15840354   train_loss = 860.690\n",
            "Epoch   4 Batch 1532160/15840354   train_loss = 900.420\n",
            "Epoch   4 Batch 1916160/15840354   train_loss = 952.002\n",
            "Epoch   4 Batch 2300160/15840354   train_loss = 833.679\n",
            "Epoch   4 Batch 2684160/15840354   train_loss = 999.651\n",
            "Epoch   4 Batch 3068160/15840354   train_loss = 868.625\n",
            "Epoch   4 Batch 3452160/15840354   train_loss = 1005.324\n",
            "Epoch   4 Batch 3836160/15840354   train_loss = 883.688\n",
            "Epoch   4 Batch 4220160/15840354   train_loss = 899.078\n",
            "Epoch   4 Batch 4604160/15840354   train_loss = 809.397\n",
            "Epoch   4 Batch 4988160/15840354   train_loss = 1049.860\n",
            "Epoch   4 Batch 5372160/15840354   train_loss = 1067.736\n",
            "Epoch   4 Batch 5756160/15840354   train_loss = 886.381\n",
            "Epoch   4 Batch 6140160/15840354   train_loss = 1037.472\n",
            "Epoch   4 Batch 6524160/15840354   train_loss = 1001.734\n",
            "Epoch   4 Batch 6908160/15840354   train_loss = 1096.250\n",
            "Epoch   4 Batch 7292160/15840354   train_loss = 930.903\n",
            "Epoch   4 Batch 7676160/15840354   train_loss = 817.625\n",
            "Epoch   4 Batch 8060160/15840354   train_loss = 893.149\n",
            "Epoch   4 Batch 8444160/15840354   train_loss = 941.866\n",
            "Epoch   4 Batch 8828160/15840354   train_loss = 883.570\n",
            "Epoch   4 Batch 9212160/15840354   train_loss = 884.926\n",
            "Epoch   4 Batch 9596160/15840354   train_loss = 919.197\n",
            "Epoch   4 Batch 9980160/15840354   train_loss = 1004.735\n",
            "Epoch   4 Batch 10364160/15840354   train_loss = 879.623\n",
            "Epoch   4 Batch 10748160/15840354   train_loss = 996.725\n",
            "Epoch   4 Batch 11132160/15840354   train_loss = 930.998\n",
            "Epoch   4 Batch 11516160/15840354   train_loss = 735.940\n",
            "Epoch   4 Batch 11900160/15840354   train_loss = 941.304\n",
            "Epoch   4 Batch 12284160/15840354   train_loss = 834.484\n",
            "Epoch   4 Batch 12668160/15840354   train_loss = 910.153\n",
            "Epoch   4 Batch 13052160/15840354   train_loss = 851.873\n",
            "Epoch   4 Batch 13436160/15840354   train_loss = 944.978\n",
            "Epoch   4 Batch 13820160/15840354   train_loss = 914.298\n",
            "Epoch   4 Batch 14204160/15840354   train_loss = 789.859\n",
            "Epoch   4 Batch 14588160/15840354   train_loss = 857.650\n",
            "Epoch   4 Batch 14972160/15840354   train_loss = 829.434\n",
            "Epoch   4 Batch 15356160/15840354   train_loss = 950.407\n",
            "Epoch   4 Batch 15740160/15840354   train_loss = 948.941\n",
            "Epoch   4 Batch 284928/3960089   test_loss = 1275.058\n",
            "Epoch   4 Batch 668928/3960089   test_loss = 1178.515\n",
            "Epoch   4 Batch 1052928/3960089   test_loss = 1172.523\n",
            "Epoch   4 Batch 1436928/3960089   test_loss = 1280.623\n",
            "Epoch   4 Batch 1820928/3960089   test_loss = 1206.879\n",
            "Epoch   4 Batch 2204928/3960089   test_loss = 1235.509\n",
            "Epoch   4 Batch 2588928/3960089   test_loss = 1302.975\n",
            "Epoch   4 Batch 2972928/3960089   test_loss = 1287.283\n",
            "Epoch   4 Batch 3356928/3960089   test_loss = 1193.077\n",
            "Epoch   4 Batch 3740928/3960089   test_loss = 1165.832\n",
            "Epoch   5 Batch 283392/15840354   train_loss = 888.977\n",
            "Epoch   5 Batch 667392/15840354   train_loss = 837.024\n",
            "Epoch   5 Batch 1051392/15840354   train_loss = 856.802\n",
            "Epoch   5 Batch 1435392/15840354   train_loss = 834.745\n",
            "Epoch   5 Batch 1819392/15840354   train_loss = 875.774\n",
            "Epoch   5 Batch 2203392/15840354   train_loss = 800.172\n",
            "Epoch   5 Batch 2587392/15840354   train_loss = 841.438\n",
            "Epoch   5 Batch 2971392/15840354   train_loss = 798.144\n",
            "Epoch   5 Batch 3355392/15840354   train_loss = 907.607\n",
            "Epoch   5 Batch 3739392/15840354   train_loss = 983.145\n",
            "Epoch   5 Batch 4123392/15840354   train_loss = 845.164\n",
            "Epoch   5 Batch 4507392/15840354   train_loss = 881.078\n",
            "Epoch   5 Batch 4891392/15840354   train_loss = 1148.819\n",
            "Epoch   5 Batch 5275392/15840354   train_loss = 725.131\n",
            "Epoch   5 Batch 5659392/15840354   train_loss = 830.221\n",
            "Epoch   5 Batch 6043392/15840354   train_loss = 1065.496\n",
            "Epoch   5 Batch 6427392/15840354   train_loss = 896.797\n",
            "Epoch   5 Batch 6811392/15840354   train_loss = 878.129\n",
            "Epoch   5 Batch 7195392/15840354   train_loss = 938.375\n",
            "Epoch   5 Batch 7579392/15840354   train_loss = 849.953\n",
            "Epoch   5 Batch 7963392/15840354   train_loss = 751.385\n",
            "Epoch   5 Batch 8347392/15840354   train_loss = 959.751\n",
            "Epoch   5 Batch 8731392/15840354   train_loss = 780.298\n",
            "Epoch   5 Batch 9115392/15840354   train_loss = 759.877\n",
            "Epoch   5 Batch 9499392/15840354   train_loss = 1013.254\n",
            "Epoch   5 Batch 9883392/15840354   train_loss = 927.097\n",
            "Epoch   5 Batch 10267392/15840354   train_loss = 966.788\n",
            "Epoch   5 Batch 10651392/15840354   train_loss = 965.860\n",
            "Epoch   5 Batch 11035392/15840354   train_loss = 821.143\n",
            "Epoch   5 Batch 11419392/15840354   train_loss = 770.405\n",
            "Epoch   5 Batch 11803392/15840354   train_loss = 921.928\n",
            "Epoch   5 Batch 12187392/15840354   train_loss = 759.631\n",
            "Epoch   5 Batch 12571392/15840354   train_loss = 911.856\n",
            "Epoch   5 Batch 12955392/15840354   train_loss = 853.833\n",
            "Epoch   5 Batch 13339392/15840354   train_loss = 884.728\n",
            "Epoch   5 Batch 13723392/15840354   train_loss = 889.237\n",
            "Epoch   5 Batch 14107392/15840354   train_loss = 895.775\n",
            "Epoch   5 Batch 14491392/15840354   train_loss = 813.687\n",
            "Epoch   5 Batch 14875392/15840354   train_loss = 893.343\n",
            "Epoch   5 Batch 15259392/15840354   train_loss = 834.050\n",
            "Epoch   5 Batch 15643392/15840354   train_loss = 864.191\n",
            "Epoch   5 Batch 164352/3960089   test_loss = 1238.232\n",
            "Epoch   5 Batch 548352/3960089   test_loss = 1105.491\n",
            "Epoch   5 Batch 932352/3960089   test_loss = 1153.055\n",
            "Epoch   5 Batch 1316352/3960089   test_loss = 1305.691\n",
            "Epoch   5 Batch 1700352/3960089   test_loss = 1147.629\n",
            "Epoch   5 Batch 2084352/3960089   test_loss = 1191.763\n",
            "Epoch   5 Batch 2468352/3960089   test_loss = 1235.190\n",
            "Epoch   5 Batch 2852352/3960089   test_loss = 1308.098\n",
            "Epoch   5 Batch 3236352/3960089   test_loss = 1224.651\n",
            "Epoch   5 Batch 3620352/3960089   test_loss = 1165.638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeha0w12uvrC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "f14b0fc6-2bfa-4249-b875-dc62f26746bf"
      },
      "source": [
        "plt.plot(losses['train'], label='Training loss')\n",
        "plt.legend()\n",
        "_ = plt.ylim()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEBERVAxERAQVAxERAf4/Glrd7zJ+E84AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgcJ_hX_-RkZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a23d5445-b675-4e3e-f241-eadb60162aa4"
      },
      "source": [
        "plt.plot(losses['test'], label='test loss')\n",
        "plt.legend()\n",
        "_ = plt.ylim()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlFJJRIO+Ukolkf8HzuI3y9tFufsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTR0PQrg-XJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model to '/content/model.pt'\n",
        "torch.save(model.state_dict(), '/content/model.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulyusRHR-nyf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1c86ccc8-9a3e-455c-d645-3e0decb6ecf6"
      },
      "source": [
        "# Load model from state_dict file '/content/model.pt'\n",
        "model = Verify_Assumption_Model()\n",
        "model.load_state_dict(torch.load('/content/model.pt', map_location='cpu'))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_rWu4Sn-zZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_relevant_movies(id, orginal=True, movie_num=10):\n",
        "    \n",
        "    movie_feature = []\n",
        "    movie_id = []\n",
        "    movie_num += 1 # because the most relevant movie is the same movie.\n",
        "    \n",
        "    # Get all movie vector, You can run quickly if you save the movie vector in your memory.\n",
        "    for key in genome_scores_dict.keys():\n",
        "        movie_id.append(key)\n",
        "        if orginal:     \n",
        "            norm = np.linalg.norm(genome_scores_dict[key],ord=2) \n",
        "            movie_feature.append(genome_scores_dict[key]/norm)\n",
        "        else:\n",
        "            v = model.movie_transfrom(torch.tensor(genome_scores_dict[key]).cuda()).cpu().detach().numpy()\n",
        "            norm = np.linalg.norm(v,ord=2) \n",
        "            movie_feature.append(v/norm)\n",
        "\n",
        "    movie_feature = torch.tensor(movie_feature).unsqueeze_(1).cuda()\n",
        "\n",
        "    if orginal: \n",
        "        norm = np.linalg.norm(genome_scores_dict[str(id)],ord=2)\n",
        "        in_movie = torch.tensor(genome_scores_dict[str(id)]/norm).expand(10381, 1128).unsqueeze_(2).cuda()\n",
        "    else:\n",
        "        v = model.movie_transfrom(torch.tensor(genome_scores_dict[str(id)]).cuda()).cpu().detach().numpy()\n",
        "        norm = np.linalg.norm(v,ord=2)\n",
        "        in_movie = torch.tensor(v/norm).cuda().expand(10381, 512).unsqueeze_(2)\n",
        "    \n",
        "    similarity = torch.bmm(movie_feature,in_movie).squeeze_(1).squeeze_(1).cpu().detach().numpy()\n",
        "    index = np.argpartition(similarity, -movie_num)[-movie_num:]\n",
        "    \n",
        "    if orginal: \n",
        "        print('Find relevant movies based on relevance vector from genome-scores.csv')\n",
        "    else:\n",
        "        print('Find relevant movies based on movie feature vector from training model')\n",
        "    \n",
        "    print('')\n",
        "    print('Input Movie: {}'.format(movies[movies['movieId']==id].values[0]))\n",
        "    print('')\n",
        "    print('Relevant Movie:')\n",
        "    \n",
        "    re = []\n",
        "    for i in index:\n",
        "        if movie_id[i] != str(id):\n",
        "            print('    {}'.format(movies[movies['movieId']==int(movie_id[i])].values[0]))\n",
        "            re.append(movie_id[i])\n",
        "            \n",
        "    return re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT_0ursG--Ln",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d59b1dba-7aee-430a-84b3-fa87496db008"
      },
      "source": [
        "get_relevant_movies(2,True)\n",
        "pass"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Find relevant movies based on relevance vector from genome-scores.csv\n",
            "\n",
            "Input Movie: [2 'Jumanji (1995)' 'Adventure|Children|Fantasy']\n",
            "\n",
            "Relevant Movie:\n",
            "    [2047 'Gnome-Mobile, The (1967)' 'Adventure|Children|Fantasy|Musical']\n",
            "    [1920 'Small Soldiers (1998)' 'Animation|Children|Fantasy|War']\n",
            "    [480 'Jurassic Park (1993)' 'Action|Adventure|Sci-Fi|Thriller']\n",
            "    [7781 'Twister (1990)' 'Comedy']\n",
            "    [455 'Free Willy (1993)' 'Adventure|Children|Drama']\n",
            "    [40851 'Zathura (2005)' 'Action|Adventure|Children|Fantasy']\n",
            "    [2429 'Mighty Joe Young (1998)' 'Action|Adventure|Drama|Fantasy|Thriller']\n",
            "    [46972 'Night at the Museum (2006)' 'Action|Comedy|Fantasy|IMAX']\n",
            "    [2054 'Honey, I Shrunk the Kids (1989)'\n",
            " 'Adventure|Children|Comedy|Fantasy|Sci-Fi']\n",
            "    [1848 'Borrowers, The (1997)' 'Adventure|Children|Comedy|Fantasy']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}